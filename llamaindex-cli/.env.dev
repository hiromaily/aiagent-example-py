# prod: use the OpenAI API
# dev:  use the local LLM server
# test: use dymmy client
APP_ENV=dev
LLM_TOOLKIT=ollama # lmstudio, ollama
#LLM_TOOLKIT=lmstudio # lmstudio, ollama

OPENAI_API_KEY=ollama # lm-studio, ollama
TAVILY_API_KEY=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
