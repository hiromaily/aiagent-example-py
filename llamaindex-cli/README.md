# llamaindex-cli

## TODO

- [ ] Local LLM mode
  - LM Studio: `baseUrl: "http://localhost:1234/v1"`
  - [LlamaIndex: LM Studio](https://docs.llamaindex.ai/en/stable/examples/llm/lmstudio/)
  - Ollama: `baseUrl: "http://localhost:11434/v1"`
- [ ] Integrate Vector Database
