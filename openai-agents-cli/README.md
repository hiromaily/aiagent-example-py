# openai-agents-cli

## TODO

- Local LLM mode
  - LM Studio: `baseUrl: "http://localhost:1234/v1"`
  - Ollama: `baseUrl: "http://localhost:11434/v1"`
- Cache
